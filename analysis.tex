\chapter{Analisi}

\normalsize
In questo capitolo verranno analizzati i risultati dell'esperimento, ottenuti utilizzando un plugin di Microsoft Excel, \textbf{XLSTAT}. La configurazione ha riguardato i valori ottenuti sui quattro dataset dai tre algoritmi di interesse: \nameref{ch:bayes}, \nameref{ch:reptree} e \nameref{ch:jrip}.

\section{Test}

Per confrontare gli algoritmi è necessario definire due ipotesi, quella nulla $H_0$ e quella alternativa $H_1$:

\begin{itemize}
	\item $H_0$: non ci sono differenze significative tra le variabili.
	\item $H_1$: almeno due variabili sono significativamente diverse tra di loro.
\end{itemize}

\noindent
Inoltre bisogna fare attenzione a scegliere lo strumento statistico adeguato, tenendo conto di alcuni aspetti:
\begin{itemize}
	\item Non possono essere fatte considerazioni sul tipo di distribuzione che i dati assumono.
	\item È necessario uno test che vada bene per più di due algoritmi.
	\item I dati non sono indipendenti tra di loro.
\end{itemize}

Per questi motivi si è scelto di utilizzare il test di \textbf{Friedman}, che è un test non-parametrico utile per gestire dati accoppiati e per funzionare con più di due algoritmi\cite{Demsar:2006:SCC:1248547.1248548}.

La metrica utilizzata è la \emph{F-Measure}, che è la media armonica di precisione e richiamo. Per fini di completezza riportiamo le relative formule:
$$Precision = \frac{True\mbox{ }Positives}{True\mbox{ }Positives + False\mbox{ }Positives}$$
$$Recall = \frac{True\mbox{ }Positives}{True\mbox{ }Positives + False\mbox{ }Negatives}$$
$$ F\mbox{-}measure = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} $$


\subsubsection*{Esecuzione}
Di seguito vengono mostrati i dati e i risultati di esecuzione del test:

\begin{table}[!htbp]
	\centering
	\begin{tabular}{|l|r|r|r|}
		\hline
		& \multicolumn{1}{l|}{NB} & \multicolumn{1}{l|}{REPTree} & \multicolumn{1}{l|}{RIPPER} \\ \hline
		german credit & 0,748 & 0,703 & 0,697 \\ \hline
		hepatitis & 0,848 & 0,72 & 0,768 \\ \hline
		vehicle & 0,422 & 0,716 & 0,68 \\ \hline
		wisconsin bc & 0,96 & 0,939 & 0,954 \\ \hline
	\end{tabular}
	\caption{F-measure dei vari dataset}
	\label{}
\end{table}

\begin{table}[!htbp]
	\centering
	\begin{tabular}{|l|r|}
		\hline
		Valore osservato & 1,500 \\ \hline
		Valore critico & 5,991 \\ \hline
		Gradi di libertà & 2 \\ \hline
		p-value & 0,472 \\ \hline
		$\alpha$ & 0,05 \\ \hline
	\end{tabular}
	\caption{Test di Friedman}
\end{table}

\clearpage

\section{Interpretazione dei risultati}

Visto che il p-value è più grande del livello di significatività $\alpha$ = 0.05, non si può rigettare l'ipotesi nulla $H_0$, quindi gli algoritmi non si comportano diversamente gli uni dagli altri in modo statisticamente significativo.
